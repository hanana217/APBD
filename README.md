# SADOP - SystÃ¨me Autonome de Diagnostic et d'Optimisation de Performance SQL

SystÃ¨me complet d'optimisation de bases de donnÃ©es MySQL utilisant **3 vrais modÃ¨les de Machine Learning** (Random Forest, XGBoost, Logistic Regression) et **Reinforcement Learning (DQN)**.

---

## ğŸš€ DÃ©marrage rapide

```bash
cd docker
docker-compose up --build
```

Une fois tous les services dÃ©marrÃ©s :

| Service       | URL                          | Description                        |
|---------------|------------------------------|------------------------------------|
| **Frontend**  | http://localhost:8501         | Interface Streamlit                |
| **Backend**   | http://localhost:8000         | API FastAPI (+ docs Swagger)       |
| **API Docs**  | http://localhost:8000/docs    | Documentation interactive Swagger  |
| **Agent RL**  | http://localhost:8002         | API de l'agent RL                  |
| **Grafana**   | http://localhost:3000         | Monitoring (admin/admin)           |
| **Prometheus**| http://localhost:9090         | MÃ©triques                          |
| **MySQL**     | localhost:3308                | Base de donnÃ©es (apbd_user/apbd_pass) |

---

## ğŸ“ Structure du projet

```
APBD/
â”œâ”€â”€ docker/                          # Infrastructure Docker
â”‚   â”œâ”€â”€ docker-compose.yml           # â­ Point d'entrÃ©e unique
â”‚   â”œâ”€â”€ mysql/
â”‚   â”‚   â””â”€â”€ my.ini                   # Configuration MySQL optimisÃ©e
â”‚   â””â”€â”€ monitoring/
â”‚       â””â”€â”€ prometheus.yml           # Configuration Prometheus
â”‚
â”œâ”€â”€ apbd_interface/                  # Application principale
â”‚   â”œâ”€â”€ backend/                     # API FastAPI
â”‚   â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”‚   â”œâ”€â”€ main.py                  # API avec 3 vrais modÃ¨les ML
â”‚   â”‚   â”œâ”€â”€ generate_dataset.py      # GÃ©nÃ©rateur de dataset d'entraÃ®nement
â”‚   â”‚   â””â”€â”€ requirements.txt
â”‚   â””â”€â”€ frontend/                    # Interface Streamlit
â”‚       â”œâ”€â”€ Dockerfile
â”‚       â”œâ”€â”€ app.py                   # Dashboard complet (7 pages)
â”‚       â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ agent/                           # Agent Reinforcement Learning
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ agent_api.py                 # API Flask de l'agent
â”‚   â”œâ”€â”€ config.py                    # Configuration (env vars)
â”‚   â”œâ”€â”€ env_enhanced.py              # Environnement Gymnasium
â”‚   â”œâ”€â”€ mysql_utils.py               # Utilitaires MySQL
â”‚   â”œâ”€â”€ train_agent.py               # Script d'entraÃ®nement DQN
â”‚   â””â”€â”€ requirements.txt
â”‚
â””â”€â”€ sql/                             # Scripts SQL
    â”œâ”€â”€ schema.sql                   # SchÃ©ma complet BDD POS + donnÃ©es
    â”œâ”€â”€ queries_bad.sql              # RequÃªtes lentes (test)
    â””â”€â”€ indexes_bad.sql              # Index sous-optimaux (test)
```

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Frontend Streamlit                  â”‚
â”‚         (Dashboard + Chat IA + 7 pages)             â”‚
â”‚                  :8501                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚ HTTP
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                Backend FastAPI                       â”‚
â”‚   3 ModÃ¨les ML : RF + XGBoost + LR                 â”‚
â”‚   Simulateur RL + Chat Agent + CSV Upload           â”‚
â”‚                  :8000                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                        â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   MySQL 8.0     â”‚    â”‚   Agent RL (DQN)    â”‚
â”‚   BDD POS       â”‚â—„â”€â”€â”€â”‚   Optimisation      â”‚
â”‚   :3306         â”‚    â”‚   d'index           â”‚
â”‚                 â”‚    â”‚   :8000 (â†’ :8002)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”§ FonctionnalitÃ©s

### ğŸ” PrÃ©diction ML (3 modÃ¨les entraÃ®nÃ©s)
- **Random Forest** ğŸŒ² : Classifieur d'ensemble robuste
- **XGBoost** ğŸš€ : Gradient boosting haute performance
- **Logistic Regression** ğŸ“ : ModÃ¨le linÃ©aire interprÃ©table
- Chaque modÃ¨le prÃ©dit si une requÃªte SQL sera **lente** ou **rapide**
- Extraction automatique de **20 features** (JOINs, sous-requÃªtes, GROUP BY, taille des tables...)
- Comparaison des 3 modÃ¨les cÃ´te Ã  cÃ´te avec mÃ©triques (accuracy, F1-score, AUC)

### ğŸ“‚ Analyse par fichier CSV
- Upload de fichiers CSV contenant des requÃªtes SQL
- PrÃ©diction batch avec les 3 modÃ¨les simultanÃ©ment
- RÃ©sumÃ© statistique des rÃ©sultats

### ğŸ¤– Optimisation RL (Reinforcement Learning)
- Agent DQN qui apprend Ã  **crÃ©er/supprimer des index**
- 3 actions : CREATE, DROP, NOOP
- RÃ©compenses basÃ©es sur l'amÃ©lioration rÃ©elle des performances
- Max 5 index simultanÃ©s

### ğŸ’¬ Assistant IA
- Chat interactif pour analyser des requÃªtes
- Suggestions d'optimisation automatique
- Recommandations d'index

### ğŸ“Š Monitoring
- Dashboard temps rÃ©el avec mÃ©triques des modÃ¨les ML
- F1-Score comparatif des 3 modÃ¨les
- Historique des optimisations
- Graphiques d'Ã©volution (Plotly)

---

## ğŸ§  Pipeline ML

1. **GÃ©nÃ©ration du dataset** : `generate_dataset.py` crÃ©e un dataset synthÃ©tique de 3000 requÃªtes SQL avec 20 features
2. **EntraÃ®nement** : Au dÃ©marrage du backend, les 3 modÃ¨les sont entraÃ®nÃ©s sur le dataset (train/test split 80/20)
3. **PrÃ©diction** : Pour chaque requÃªte SQL, les features sont extraites puis passÃ©es aux 3 modÃ¨les
4. **Fallback** : Si `generate_dataset.py` Ã©choue, un dataset minimal de 1000 lignes est gÃ©nÃ©rÃ© automatiquement

---

## âš™ï¸ Configuration

Toutes les configurations se font via **variables d'environnement** (dÃ©finies dans le `docker-compose.yml`) :

| Variable         | DÃ©faut       | Description              |
|------------------|-------------|--------------------------|
| `MYSQL_HOST`     | `mysql`     | HÃ´te de la BDD           |
| `MYSQL_PORT`     | `3306`      | Port de la BDD           |
| `MYSQL_USER`     | `apbd_user` | Utilisateur MySQL        |
| `MYSQL_PASSWORD`  | `apbd_pass` | Mot de passe MySQL       |
| `MYSQL_DATABASE`  | `pos`       | Nom de la base           |
| `BACKEND_URL`    | `http://backend:8000` | URL du backend (frontend) |

---

## ğŸ›‘ ArrÃªt

```bash
cd docker
docker-compose down
```

Pour supprimer aussi les donnÃ©es :
```bash
docker-compose down -v
```

---

## ğŸ“¦ Base de donnÃ©es POS

Tables principales : `admin`, `clients`, `wilayas`, `products`, `promotions`, `offers`, `cart`, `orders`, `claims`, `comments`, `rating`, `favorites`, `returns`, `inbox`, `query_logs`

---

**SADOP v5.0** | Â© APBD Team


